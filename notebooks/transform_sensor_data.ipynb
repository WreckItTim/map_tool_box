{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d3ce3f-5b84-4f12-8f8e-f778018f25b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from map_tool_box.transformation_tools import transformations\n",
    "from map_tool_box.datamap_tools import datamap\n",
    "from map_tool_box.utils import utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a4fdb7-7f2e-4ce0-a65e-135e95516adb",
   "metadata": {},
   "source": [
    "# transform data from a given sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62da1ec8-5f94-44e2-b9c7-abc06db3aa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_name = 'AirSimNH' # given map to fetch data from\n",
    "input_sensor = 'SceneV1' # input sensor data\n",
    "output_sensor = 'SceneV1b' # output sensor data (will write to corresponding directory)\n",
    "transformation = transformations.switch_bgr_and_rgb # transformation function to apply to each data point\n",
    "transformation_parameters = {} # optional transformation kwargs \n",
    "\n",
    "# transform only one specific data_dict from given sensor\n",
    "    # data_dicts are data PARTS of whole data_maps (for large file systems) that follow:\n",
    "    # {x: {y: {z: {d:observation} } } }\n",
    "    # x,y,z are spatial coords and d is an arbitrary directional value\n",
    "    # the filenames of the data_dict describe the x,y,z range of values collected within the file\n",
    "part_name = '-16_16_-16_16_4_5' # x:[-16,16) y:[-16,16) z:[4,5)\n",
    "data_dict = datamap.read_data_dict(map_name, input_sensor, part_name)\n",
    "transformed_data_dict = datamap.transform_data_dict(data_dict, transformation, transformation_parameters)\n",
    "datamap.write_data_dict(map_name, output_sensor, transformed_data_dict, part_name)\n",
    "\n",
    "# transform all data from given sensor (there is about a total of 100gb of SceneV1 data)\n",
    "#datamap.transform_sensor(map_name, input_sensor, output_sensor, transformation, transformation_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0b9c81-5246-487d-aa6b-fdd4c9822dfe",
   "metadata": {},
   "source": [
    "# view data before and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ce6a0a-ab45-4858-af71-3a31cd22f021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use data tool and set map to fetch data from\n",
    "data_map = datamap.DataMapRoof(map_name)\n",
    "\n",
    "# we will fetch one data point from the given coordinates\n",
    "x, y, z, direction = 0, 0, 4, 0\n",
    "\n",
    "# fetch data\n",
    "before = data_map.get_data_point(x=x, y=y, z=z, direction=direction, sensor_name=input_sensor)\n",
    "after = data_map.get_data_point(x=x, y=y, z=z, direction=direction, sensor_name=output_sensor)\n",
    "\n",
    "# visualize data\n",
    "fig, axs = plt.subplots(ncols=2)\n",
    "\n",
    "ax = axs[0]\n",
    "ax.imshow(transformations.channel_first_to_last(before))\n",
    "ax.set_title('RGB Image')\n",
    "ax.axis('off')\n",
    "\n",
    "ax = axs[1]\n",
    "ax.set_title('BGR Image')\n",
    "ax.imshow(transformations.channel_first_to_last(after))\n",
    "ax.axis('off')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcb046d-cc90-480f-9b53-36eca63b775b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
